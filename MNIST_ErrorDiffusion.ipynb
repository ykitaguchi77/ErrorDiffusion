{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxC/wPVtuohxTxnda7S5VA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/ErrorDiffusion/blob/main/MNIST_ErrorDiffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Error Diffusion MNIST**\n",
        "\n",
        "https://qiita.com/pocokhc/items/f7ab56051bb936740b8f"
      ],
      "metadata": {
        "id": "W9rgWeoZxf8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import math\n",
        "import random\n",
        "\n",
        "random.seed(10)  # 乱数のシードを設定\n",
        "\n",
        "\n",
        "def sign(x):  # 符号関数の定義\n",
        "    if x == 0:\n",
        "        return 0\n",
        "    return 1 if x > 0 else -1\n",
        "\n",
        "\n",
        "def relu(x):  # ReLU関数の定義\n",
        "    return x if x > 0 else 0\n",
        "\n",
        "\n",
        "def relu_derivative(x):  # ReLU関数の導関数の定義\n",
        "    return 1 if x > 0 else 0\n",
        "\n",
        "\n",
        "def sigmoid(x, u0=0.4):  # シグモイド関数の定義\n",
        "    return 1 / (1 + math.exp(-2 * x / u0))\n",
        "\n",
        "\n",
        "def sigmoid_derivative(x):  # シグモイド関数の導関数の定義\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "\n",
        "def linear(x):  # 線形関数の定義\n",
        "    return x\n",
        "\n",
        "\n",
        "def linear_derivative(x):  # 線形関数の導関数の定義\n",
        "    return 1\n",
        "\n",
        "\n",
        "class Neuron:  # ニューロンクラスの定義\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_neurons: list[\"Neuron\"],  # 入力ニューロンのリスト\n",
        "        ntype: str,  # ニューロンのタイプ（\"p\": positive, \"n\": negative）\n",
        "        alpha: float = 0.8,  # 学習率\n",
        "        activation=sigmoid,  # 活性化関数\n",
        "        activation_derivative=sigmoid_derivative,  # 活性化関数の導関数\n",
        "    ) -> None:\n",
        "        self.ntype = ntype\n",
        "        self.alpha = alpha\n",
        "        self.activation = activation\n",
        "        self.activation_derivative = activation_derivative\n",
        "\n",
        "        # --- 重みの初期化\n",
        "        self.weights = []\n",
        "        for n in in_neurons:\n",
        "            if ntype == \"p\":\n",
        "                if n.ntype == \"p\":\n",
        "                    ope = 1\n",
        "                else:\n",
        "                    ope = -1\n",
        "            else:\n",
        "                if n.ntype == \"p\":\n",
        "                    ope = -1\n",
        "                else:\n",
        "                    ope = 1\n",
        "            self.weights.append(random.random() * ope)\n",
        "\n",
        "        # --- 演算子の設定\n",
        "        self.operator = 1 if ntype == \"p\" else -1\n",
        "        self.weights_operator = [n.operator for n in in_neurons]\n",
        "\n",
        "        # --- 更新インデックスの設定\n",
        "        self.upper_idx_list = []\n",
        "        self.lower_idx_list = []\n",
        "        for i, n in enumerate(in_neurons):\n",
        "            if n.ntype == \"p\":\n",
        "                self.upper_idx_list.append(i)\n",
        "            else:\n",
        "                self.lower_idx_list.append(i)\n",
        "\n",
        "    def forward(self, x):  # 順伝播の計算\n",
        "        assert len(self.weights) == len(x)\n",
        "        y = [x[i] * self.weights[i] for i in range(len(self.weights))]\n",
        "        y = sum(y)\n",
        "        self.prev_in = x\n",
        "        self.prev_out = y\n",
        "        y = self.activation(y)\n",
        "        return y\n",
        "\n",
        "    def update_weight(self, delta_out, direct: str):  # 重みの更新\n",
        "        grad = self.activation_derivative(abs(self.prev_out))\n",
        "\n",
        "        if direct == \"upper\":\n",
        "            indices = self.upper_idx_list\n",
        "        else:\n",
        "            indices = self.lower_idx_list\n",
        "\n",
        "        for idx in indices:\n",
        "            _old_w = self.weights[idx]\n",
        "            delta = self.alpha * self.prev_in[idx]\n",
        "            delta *= grad\n",
        "            delta *= delta_out * self.operator * self.weights_operator[idx]\n",
        "            self.weights[idx] += delta\n",
        "\n",
        "            # --- デバッグ用の出力\n",
        "            s = f\"{idx:2d}\"\n",
        "            s += f\", ot_in {self.prev_in[idx]:5.2f}\"\n",
        "            s += f\", f'({self.prev_out:5.2f})={grad:5.2f}\"\n",
        "            s += f\", del_ot {delta_out:5.2f}\"\n",
        "            s += f\", d {delta:6.3f}\"\n",
        "            s += f\", {self.operator:2d} {self.weights_operator[idx]:2d}\"\n",
        "            s += f\", w {_old_w:5.2f} -> {self.weights[idx]:5.2f}\"\n",
        "            # print(s)\n",
        "\n",
        "    def __str__(self):  # ニューロンの情報を文字列で返す\n",
        "        s = f\"{self.ntype} {self.operator:2d}\"\n",
        "        arr = []\n",
        "        for i in range(len(self.weights)):\n",
        "            o = \"+\" if i in self.upper_idx_list else \"-\"\n",
        "            arr.append(f\"{self.weights[i]:6.3f}({self.weights_operator[i]:2d},{o})\")\n",
        "        s += \" [\" + \", \".join(arr) + \"]\"\n",
        "        return s\n",
        "\n",
        "\n",
        "class ThreeLayerModel:  # 3層ニューラルネットワークモデルの定義\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_num: int,  # 入力層のニューロン数\n",
        "        hidden_num: int,  # 中間層のニューロン数\n",
        "        alpha: float = 0.8,  # 学習率\n",
        "        beta: float = 0.8,  # バイアス\n",
        "    ) -> None:\n",
        "        self.beta = beta\n",
        "\n",
        "        # 中間層のバイアスニューロン\n",
        "        hd_p = Neuron([], \"p\")\n",
        "        hd_n = Neuron([], \"n\")\n",
        "\n",
        "        # 入力層のニューロン\n",
        "        inputs: list[Neuron] = []\n",
        "        for i in range(input_num):\n",
        "            inputs.append(Neuron([], \"p\"))\n",
        "            inputs.append(Neuron([], \"n\"))\n",
        "\n",
        "        # 中間層のニューロン\n",
        "        self.hidden_neurons: list[Neuron] = []\n",
        "        for i in range(hidden_num):\n",
        "            self.hidden_neurons.append(\n",
        "                Neuron(\n",
        "                    [hd_p, hd_n] + inputs,\n",
        "                    ntype=(\"p\" if i % 2 == 1 else \"n\"),\n",
        "                    alpha=alpha,\n",
        "                    activation=sigmoid,\n",
        "                    activation_derivative=sigmoid_derivative,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # 出力層のニューロン\n",
        "        self.out_neuron = Neuron(\n",
        "            [hd_p, hd_n] + self.hidden_neurons,\n",
        "            \"p\",\n",
        "            alpha=alpha,\n",
        "            activation=sigmoid,\n",
        "            activation_derivative=sigmoid_derivative,\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):  # 順伝播の計算\n",
        "        # 入力層\n",
        "        x = []\n",
        "        for n in inputs:\n",
        "            x.append(n)  # p\n",
        "            x.append(n)  # n\n",
        "\n",
        "        # 中間層\n",
        "        x = [h.forward([self.beta, self.beta] + x) for h in self.hidden_neurons]\n",
        "\n",
        "        # 出力層\n",
        "        x = self.out_neuron.forward([self.beta, self.beta] + x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def train(self, inputs, target):  # 学習\n",
        "        x = self.forward(inputs)\n",
        "\n",
        "        # --- 重みの更新（ED法）\n",
        "        diff = target - x\n",
        "        if diff > 0:\n",
        "            direct = \"upper\"\n",
        "        else:\n",
        "            direct = \"lower\"\n",
        "            diff = -diff\n",
        "        self.out_neuron.update_weight(diff, direct)\n",
        "        for h in self.hidden_neurons:\n",
        "            h.update_weight(diff, direct)\n",
        "\n",
        "        return diff\n",
        "\n",
        "\n",
        "def main_one():  # 恒等関数の学習\n",
        "    model = ThreeLayerModel(1, hidden_num=1)\n",
        "\n",
        "    # --- 学習ループ\n",
        "    dataset = [\n",
        "        [0, 1],\n",
        "        [1, 1],\n",
        "    ]\n",
        "    for i in range(100):\n",
        "        x, target = dataset[random.randint(0, len(dataset)) - 1]\n",
        "        metric = model.train([x], target)\n",
        "\n",
        "        # --- 予測\n",
        "        y = model.forward([x])\n",
        "        print(f\"{i} in{x:5.2f} -> {y:5.2f}, target {target:5.2f}, metric {metric:5.2f}\")\n",
        "\n",
        "    print(\"--- result ---\")\n",
        "    for x, target in dataset:\n",
        "        y = model.forward([x])\n",
        "        print(f\"{x:5.2f} -> {y:5.2f}, target {target:5.2f}\")\n",
        "\n",
        "    # --- 最終的な重み\n",
        "    print(\"--- weights ---\")\n",
        "    print(model.out_neuron)\n",
        "    for n in model.hidden_neurons:\n",
        "        print(n)\n",
        "\n",
        "\n",
        "def main_not():  # NOT関数の学習\n",
        "    model = ThreeLayerModel(1, hidden_num=2)\n",
        "\n",
        "    # --- 学習ループ\n",
        "    dataset = [\n",
        "        [0, 1],\n",
        "        [1, 0],\n",
        "    ]\n",
        "    for i in range(100):\n",
        "        x, target = dataset[random.randint(0, len(dataset)) - 1]\n",
        "        metric = model.train([x], target)\n",
        "\n",
        "        # --- 予測\n",
        "        y = model.forward([x])\n",
        "        print(f\"{i} in{x:5.2f} -> {y:5.2f}, target {target:5.2f}, metric {metric:5.2f}\")\n",
        "\n",
        "    print(\"--- result ---\")\n",
        "    for x, target in dataset:\n",
        "        y = model.forward([x])\n",
        "        print(f\"{x:5.2f} -> {y:5.2f}, target {target:5.2f}\")\n",
        "\n",
        "    # --- 最終的な重み\n",
        "    print(\"--- weights ---\")\n",
        "    print(model.out_neuron)\n",
        "    for n in model.hidden_neurons:\n",
        "        print(n)\n",
        "\n",
        "\n",
        "def main_xor():  # XOR関数の学習\n",
        "    model = ThreeLayerModel(2, hidden_num=16)\n",
        "\n",
        "    # --- 学習ループ\n",
        "    dataset = [\n",
        "        [0, 0, 1.0],\n",
        "        [1, 0, 0.0],\n",
        "        [0, 1, 0.0],\n",
        "        [1, 1, 1.0],\n",
        "    ]\n",
        "    for i in range(100):\n",
        "        x1, x2, target = dataset[random.randint(0, len(dataset)) - 1]\n",
        "        metric = model.train([x1, x2], target)\n",
        "\n",
        "        # --- 予測\n",
        "        y = model.forward([x1, x2])\n",
        "        print(f\"{i} in[{x1:5.2f},{x2:5.2f}] -> {y:5.2f}, target {target:5.2f}, metric {metric:5.2f}\")\n",
        "\n",
        "    print(\"--- result ---\")\n",
        "    for x1, x2, target in dataset:\n",
        "        y = model.forward([x1, x2])\n",
        "        print(f\"[{x1:5.2f},{x2:5.2f}] -> {y:5.2f}, target {target:5.2f}\")\n",
        "\n",
        "    # --- 最終的な重み\n",
        "    print(\"--- weights ---\")\n",
        "    print(model.out_neuron)\n",
        "    for n in model.hidden_neurons:\n",
        "        print(n)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_one()  # 恒等関数の学習を実行\n",
        "    main_not()  # NOT関数の学習を実行\n",
        "    main_xor()  # XOR関数の学習を実行\n",
        "```"
      ],
      "metadata": {
        "id": "Fw9Ov_rq2_Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Input(shape=(28 * 28)),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_one()\n",
        "    main_not()\n",
        "    main_xor()"
      ],
      "metadata": {
        "id": "JBmAhntPBhfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ikH16vOJBpC4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}