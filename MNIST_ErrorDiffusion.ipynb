{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPGdn1QNFnUSqGwMiiZipn5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/ErrorDiffusion/blob/main/MNIST_ErrorDiffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Error Diffusion MNIST**\n",
        "\n",
        "https://qiita.com/pocokhc/items/f7ab56051bb936740b8f"
      ],
      "metadata": {
        "id": "W9rgWeoZxf8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import math\n",
        "import random\n",
        "\n",
        "random.seed(10)  # 乱数のシードを設定\n",
        "\n",
        "\n",
        "def sign(x):  # 符号関数の定義\n",
        "    if x == 0:\n",
        "        return 0\n",
        "    return 1 if x > 0 else -1\n",
        "\n",
        "\n",
        "def relu(x):  # ReLU関数の定義\n",
        "    return x if x > 0 else 0\n",
        "\n",
        "\n",
        "def relu_derivative(x):  # ReLU関数の導関数の定義\n",
        "    return 1 if x > 0 else 0\n",
        "\n",
        "\n",
        "def sigmoid(x, u0=0.4):  # シグモイド関数の定義\n",
        "    return 1 / (1 + math.exp(-2 * x / u0))\n",
        "\n",
        "\n",
        "def sigmoid_derivative(x):  # シグモイド関数の導関数の定義\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "\n",
        "def linear(x):  # 線形関数の定義\n",
        "    return x\n",
        "\n",
        "\n",
        "def linear_derivative(x):  # 線形関数の導関数の定義\n",
        "    return 1\n",
        "\n",
        "\n",
        "class Neuron:  # ニューロンクラスの定義\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_neurons: list[\"Neuron\"],  # 入力ニューロンのリスト\n",
        "        ntype: str,  # ニューロンのタイプ（\"p\": positive, \"n\": negative）\n",
        "        alpha: float = 0.8,  # 学習率\n",
        "        activation=sigmoid,  # 活性化関数\n",
        "        activation_derivative=sigmoid_derivative,  # 活性化関数の導関数\n",
        "    ) -> None:\n",
        "        self.ntype = ntype\n",
        "        self.alpha = alpha\n",
        "        self.activation = activation\n",
        "        self.activation_derivative = activation_derivative\n",
        "\n",
        "        # --- 重みの初期化\n",
        "        self.weights = []\n",
        "        for n in in_neurons:\n",
        "            if ntype == \"p\":\n",
        "                if n.ntype == \"p\":\n",
        "                    ope = 1\n",
        "                else:\n",
        "                    ope = -1\n",
        "            else:\n",
        "                if n.ntype == \"p\":\n",
        "                    ope = -1\n",
        "                else:\n",
        "                    ope = 1\n",
        "            self.weights.append(random.random() * ope)\n",
        "\n",
        "        # --- 演算子の設定\n",
        "        self.operator = 1 if ntype == \"p\" else -1\n",
        "        self.weights_operator = [n.operator for n in in_neurons]\n",
        "\n",
        "        # --- 更新インデックスの設定\n",
        "        self.upper_idx_list = []\n",
        "        self.lower_idx_list = []\n",
        "        for i, n in enumerate(in_neurons):\n",
        "            if n.ntype == \"p\":\n",
        "                self.upper_idx_list.append(i)\n",
        "            else:\n",
        "                self.lower_idx_list.append(i)\n",
        "\n",
        "    def forward(self, x):  # 順伝播の計算\n",
        "        assert len(self.weights) == len(x)\n",
        "        y = [x[i] * self.weights[i] for i in range(len(self.weights))]\n",
        "        y = sum(y)\n",
        "        self.prev_in = x\n",
        "        self.prev_out = y\n",
        "        y = self.activation(y)\n",
        "        return y\n",
        "\n",
        "    def update_weight(self, delta_out, direct: str):  # 重みの更新\n",
        "        grad = self.activation_derivative(abs(self.prev_out))\n",
        "\n",
        "        if direct == \"upper\":\n",
        "            indices = self.upper_idx_list\n",
        "        else:\n",
        "            indices = self.lower_idx_list\n",
        "\n",
        "        for idx in indices:\n",
        "            _old_w = self.weights[idx]\n",
        "            delta = self.alpha * self.prev_in[idx]\n",
        "            delta *= grad\n",
        "            delta *= delta_out * self.operator * self.weights_operator[idx]\n",
        "            self.weights[idx] += delta\n",
        "\n",
        "            # --- デバッグ用の出力\n",
        "            s = f\"{idx:2d}\"\n",
        "            s += f\", ot_in {self.prev_in[idx]:5.2f}\"\n",
        "            s += f\", f'({self.prev_out:5.2f})={grad:5.2f}\"\n",
        "            s += f\", del_ot {delta_out:5.2f}\"\n",
        "            s += f\", d {delta:6.3f}\"\n",
        "            s += f\", {self.operator:2d} {self.weights_operator[idx]:2d}\"\n",
        "            s += f\", w {_old_w:5.2f} -> {self.weights[idx]:5.2f}\"\n",
        "            # print(s)\n",
        "\n",
        "    def __str__(self):  # ニューロンの情報を文字列で返す\n",
        "        s = f\"{self.ntype} {self.operator:2d}\"\n",
        "        arr = []\n",
        "        for i in range(len(self.weights)):\n",
        "            o = \"+\" if i in self.upper_idx_list else \"-\"\n",
        "            arr.append(f\"{self.weights[i]:6.3f}({self.weights_operator[i]:2d},{o})\")\n",
        "        s += \" [\" + \", \".join(arr) + \"]\"\n",
        "        return s\n",
        "\n",
        "\n",
        "class ThreeLayerModel:  # 3層ニューラルネットワークモデルの定義\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_num: int,  # 入力層のニューロン数\n",
        "        hidden_num: int,  # 中間層のニューロン数\n",
        "        alpha: float = 0.8,  # 学習率\n",
        "        beta: float = 0.8,  # バイアス\n",
        "    ) -> None:\n",
        "        self.beta = beta\n",
        "\n",
        "        # 中間層のバイアスニューロン\n",
        "        hd_p = Neuron([], \"p\")\n",
        "        hd_n = Neuron([], \"n\")\n",
        "\n",
        "        # 入力層のニューロン\n",
        "        inputs: list[Neuron] = []\n",
        "        for i in range(input_num):\n",
        "            inputs.append(Neuron([], \"p\"))\n",
        "            inputs.append(Neuron([], \"n\"))\n",
        "\n",
        "        # 中間層のニューロン\n",
        "        self.hidden_neurons: list[Neuron] = []\n",
        "        for i in range(hidden_num):\n",
        "            self.hidden_neurons.append(\n",
        "                Neuron(\n",
        "                    [hd_p, hd_n] + inputs,\n",
        "                    ntype=(\"p\" if i % 2 == 1 else \"n\"),\n",
        "                    alpha=alpha,\n",
        "                    activation=sigmoid,\n",
        "                    activation_derivative=sigmoid_derivative,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # 出力層のニューロン\n",
        "        self.out_neuron = Neuron(\n",
        "            [hd_p, hd_n] + self.hidden_neurons,\n",
        "            \"p\",\n",
        "            alpha=alpha,\n",
        "            activation=sigmoid,\n",
        "            activation_derivative=sigmoid_derivative,\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):  # 順伝播の計算\n",
        "        # 入力層\n",
        "        x = []\n",
        "        for n in inputs:\n",
        "            x.append(n)  # p\n",
        "            x.append(n)  # n\n",
        "\n",
        "        # 中間層\n",
        "        x = [h.forward([self.beta, self.beta] + x) for h in self.hidden_neurons]\n",
        "\n",
        "        # 出力層\n",
        "        x = self.out_neuron.forward([self.beta, self.beta] + x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def train(self, inputs, target):  # 学習\n",
        "        x = self.forward(inputs)\n",
        "\n",
        "        # --- 重みの更新（ED法）\n",
        "        diff = target - x\n",
        "        if diff > 0:\n",
        "            direct = \"upper\"\n",
        "        else:\n",
        "            direct = \"lower\"\n",
        "            diff = -diff\n",
        "        self.out_neuron.update_weight(diff, direct)\n",
        "        for h in self.hidden_neurons:\n",
        "            h.update_weight(diff, direct)\n",
        "\n",
        "        return diff\n",
        "\n",
        "\n",
        "def main_one():  # 恒等関数の学習\n",
        "    model = ThreeLayerModel(1, hidden_num=1)\n",
        "\n",
        "    # --- 学習ループ\n",
        "    dataset = [\n",
        "        [0, 1],\n",
        "        [1, 1],\n",
        "    ]\n",
        "    for i in range(100):\n",
        "        x, target = dataset[random.randint(0, len(dataset)) - 1]\n",
        "        metric = model.train([x], target)\n",
        "\n",
        "        # --- 予測\n",
        "        y = model.forward([x])\n",
        "        print(f\"{i} in{x:5.2f} -> {y:5.2f}, target {target:5.2f}, metric {metric:5.2f}\")\n",
        "\n",
        "    print(\"--- result ---\")\n",
        "    for x, target in dataset:\n",
        "        y = model.forward([x])\n",
        "        print(f\"{x:5.2f} -> {y:5.2f}, target {target:5.2f}\")\n",
        "\n",
        "    # --- 最終的な重み\n",
        "    print(\"--- weights ---\")\n",
        "    print(model.out_neuron)\n",
        "    for n in model.hidden_neurons:\n",
        "        print(n)\n",
        "\n",
        "\n",
        "def main_not():  # NOT関数の学習\n",
        "    model = ThreeLayerModel(1, hidden_num=2)\n",
        "\n",
        "    # --- 学習ループ\n",
        "    dataset = [\n",
        "        [0, 1],\n",
        "        [1, 0],\n",
        "    ]\n",
        "    for i in range(100):\n",
        "        x, target = dataset[random.randint(0, len(dataset)) - 1]\n",
        "        metric = model.train([x], target)\n",
        "\n",
        "        # --- 予測\n",
        "        y = model.forward([x])\n",
        "        print(f\"{i} in{x:5.2f} -> {y:5.2f}, target {target:5.2f}, metric {metric:5.2f}\")\n",
        "\n",
        "    print(\"--- result ---\")\n",
        "    for x, target in dataset:\n",
        "        y = model.forward([x])\n",
        "        print(f\"{x:5.2f} -> {y:5.2f}, target {target:5.2f}\")\n",
        "\n",
        "    # --- 最終的な重み\n",
        "    print(\"--- weights ---\")\n",
        "    print(model.out_neuron)\n",
        "    for n in model.hidden_neurons:\n",
        "        print(n)\n",
        "\n",
        "\n",
        "def main_xor():  # XOR関数の学習\n",
        "    model = ThreeLayerModel(2, hidden_num=16)\n",
        "\n",
        "    # --- 学習ループ\n",
        "    dataset = [\n",
        "        [0, 0, 1.0],\n",
        "        [1, 0, 0.0],\n",
        "        [0, 1, 0.0],\n",
        "        [1, 1, 1.0],\n",
        "    ]\n",
        "    for i in range(100):\n",
        "        x1, x2, target = dataset[random.randint(0, len(dataset)) - 1]\n",
        "        metric = model.train([x1, x2], target)\n",
        "\n",
        "        # --- 予測\n",
        "        y = model.forward([x1, x2])\n",
        "        print(f\"{i} in[{x1:5.2f},{x2:5.2f}] -> {y:5.2f}, target {target:5.2f}, metric {metric:5.2f}\")\n",
        "\n",
        "    print(\"--- result ---\")\n",
        "    for x1, x2, target in dataset:\n",
        "        y = model.forward([x1, x2])\n",
        "        print(f\"[{x1:5.2f},{x2:5.2f}] -> {y:5.2f}, target {target:5.2f}\")\n",
        "\n",
        "    # --- 最終的な重み\n",
        "    print(\"--- weights ---\")\n",
        "    print(model.out_neuron)\n",
        "    for n in model.hidden_neurons:\n",
        "        print(n)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_one()  # 恒等関数の学習を実行\n",
        "    main_not()  # NOT関数の学習を実行\n",
        "    main_xor()  # XOR関数の学習を実行"
      ],
      "metadata": {
        "id": "Fw9Ov_rq2_Uf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9ab6500-2df3-4d08-9242-c98cf8a20e3b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 in 1.00 ->  0.53, target  1.00, metric  0.58\n",
            "1 in 1.00 ->  0.61, target  1.00, metric  0.47\n",
            "2 in 1.00 ->  0.67, target  1.00, metric  0.39\n",
            "3 in 0.00 ->  0.59, target  1.00, metric  0.54\n",
            "4 in 0.00 ->  0.68, target  1.00, metric  0.41\n",
            "5 in 1.00 ->  0.81, target  1.00, metric  0.20\n",
            "6 in 1.00 ->  0.82, target  1.00, metric  0.19\n",
            "7 in 1.00 ->  0.83, target  1.00, metric  0.18\n",
            "8 in 0.00 ->  0.77, target  1.00, metric  0.27\n",
            "9 in 1.00 ->  0.86, target  1.00, metric  0.15\n",
            "10 in 0.00 ->  0.80, target  1.00, metric  0.22\n",
            "11 in 1.00 ->  0.87, target  1.00, metric  0.13\n",
            "12 in 1.00 ->  0.88, target  1.00, metric  0.13\n",
            "13 in 0.00 ->  0.83, target  1.00, metric  0.19\n",
            "14 in 0.00 ->  0.84, target  1.00, metric  0.17\n",
            "15 in 0.00 ->  0.85, target  1.00, metric  0.16\n",
            "16 in 0.00 ->  0.86, target  1.00, metric  0.15\n",
            "17 in 1.00 ->  0.90, target  1.00, metric  0.10\n",
            "18 in 0.00 ->  0.87, target  1.00, metric  0.14\n",
            "19 in 0.00 ->  0.87, target  1.00, metric  0.13\n",
            "20 in 1.00 ->  0.91, target  1.00, metric  0.09\n",
            "21 in 1.00 ->  0.91, target  1.00, metric  0.09\n",
            "22 in 0.00 ->  0.88, target  1.00, metric  0.12\n",
            "23 in 1.00 ->  0.92, target  1.00, metric  0.08\n",
            "24 in 0.00 ->  0.89, target  1.00, metric  0.11\n",
            "25 in 1.00 ->  0.92, target  1.00, metric  0.08\n",
            "26 in 0.00 ->  0.89, target  1.00, metric  0.11\n",
            "27 in 1.00 ->  0.92, target  1.00, metric  0.08\n",
            "28 in 0.00 ->  0.90, target  1.00, metric  0.10\n",
            "29 in 1.00 ->  0.93, target  1.00, metric  0.07\n",
            "30 in 0.00 ->  0.90, target  1.00, metric  0.10\n",
            "31 in 1.00 ->  0.93, target  1.00, metric  0.07\n",
            "32 in 1.00 ->  0.93, target  1.00, metric  0.07\n",
            "33 in 1.00 ->  0.93, target  1.00, metric  0.07\n",
            "34 in 1.00 ->  0.93, target  1.00, metric  0.07\n",
            "35 in 1.00 ->  0.93, target  1.00, metric  0.07\n",
            "36 in 1.00 ->  0.93, target  1.00, metric  0.07\n",
            "37 in 0.00 ->  0.91, target  1.00, metric  0.09\n",
            "38 in 1.00 ->  0.94, target  1.00, metric  0.07\n",
            "39 in 0.00 ->  0.91, target  1.00, metric  0.09\n",
            "40 in 1.00 ->  0.94, target  1.00, metric  0.06\n",
            "41 in 0.00 ->  0.92, target  1.00, metric  0.08\n",
            "42 in 1.00 ->  0.94, target  1.00, metric  0.06\n",
            "43 in 1.00 ->  0.94, target  1.00, metric  0.06\n",
            "44 in 0.00 ->  0.92, target  1.00, metric  0.08\n",
            "45 in 0.00 ->  0.92, target  1.00, metric  0.08\n",
            "46 in 0.00 ->  0.92, target  1.00, metric  0.08\n",
            "47 in 1.00 ->  0.94, target  1.00, metric  0.06\n",
            "48 in 1.00 ->  0.94, target  1.00, metric  0.06\n",
            "49 in 1.00 ->  0.94, target  1.00, metric  0.06\n",
            "50 in 0.00 ->  0.93, target  1.00, metric  0.08\n",
            "51 in 1.00 ->  0.94, target  1.00, metric  0.06\n",
            "52 in 1.00 ->  0.94, target  1.00, metric  0.06\n",
            "53 in 1.00 ->  0.94, target  1.00, metric  0.06\n",
            "54 in 0.00 ->  0.93, target  1.00, metric  0.07\n",
            "55 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "56 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "57 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "58 in 0.00 ->  0.93, target  1.00, metric  0.07\n",
            "59 in 0.00 ->  0.93, target  1.00, metric  0.07\n",
            "60 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "61 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "62 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "63 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "64 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "65 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "66 in 0.00 ->  0.94, target  1.00, metric  0.07\n",
            "67 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "68 in 0.00 ->  0.94, target  1.00, metric  0.06\n",
            "69 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "70 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "71 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "72 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "73 in 0.00 ->  0.94, target  1.00, metric  0.06\n",
            "74 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "75 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "76 in 0.00 ->  0.94, target  1.00, metric  0.06\n",
            "77 in 0.00 ->  0.94, target  1.00, metric  0.06\n",
            "78 in 0.00 ->  0.94, target  1.00, metric  0.06\n",
            "79 in 0.00 ->  0.94, target  1.00, metric  0.06\n",
            "80 in 1.00 ->  0.95, target  1.00, metric  0.05\n",
            "81 in 1.00 ->  0.96, target  1.00, metric  0.05\n",
            "82 in 0.00 ->  0.94, target  1.00, metric  0.06\n",
            "83 in 1.00 ->  0.96, target  1.00, metric  0.04\n",
            "84 in 1.00 ->  0.96, target  1.00, metric  0.04\n",
            "85 in 1.00 ->  0.96, target  1.00, metric  0.04\n",
            "86 in 1.00 ->  0.96, target  1.00, metric  0.04\n",
            "87 in 1.00 ->  0.96, target  1.00, metric  0.04\n",
            "88 in 0.00 ->  0.95, target  1.00, metric  0.06\n",
            "89 in 0.00 ->  0.95, target  1.00, metric  0.05\n",
            "90 in 0.00 ->  0.95, target  1.00, metric  0.05\n",
            "91 in 1.00 ->  0.96, target  1.00, metric  0.04\n",
            "92 in 1.00 ->  0.96, target  1.00, metric  0.04\n",
            "93 in 1.00 ->  0.96, target  1.00, metric  0.04\n",
            "94 in 1.00 ->  0.96, target  1.00, metric  0.04\n",
            "95 in 1.00 ->  0.96, target  1.00, metric  0.04\n",
            "96 in 0.00 ->  0.95, target  1.00, metric  0.05\n",
            "97 in 0.00 ->  0.95, target  1.00, metric  0.05\n",
            "98 in 0.00 ->  0.95, target  1.00, metric  0.05\n",
            "99 in 0.00 ->  0.95, target  1.00, metric  0.05\n",
            "--- result ---\n",
            " 0.00 ->  0.95, target  1.00\n",
            " 1.00 ->  0.96, target  1.00\n",
            "--- weights ---\n",
            "p  1 [ 1.620( 1,+), -0.824(-1,-), -0.653(-1,-)]\n",
            "n -1 [-1.045( 1,+),  0.429(-1,-), -0.694( 1,+),  0.206(-1,-)]\n",
            "0 in 0.00 ->  0.71, target  1.00, metric  0.51\n",
            "1 in 1.00 ->  0.34, target  0.00, metric  0.68\n",
            "2 in 0.00 ->  0.72, target  1.00, metric  0.54\n",
            "3 in 1.00 ->  0.22, target  0.00, metric  0.54\n",
            "4 in 0.00 ->  0.75, target  1.00, metric  0.51\n",
            "5 in 1.00 ->  0.17, target  0.00, metric  0.39\n",
            "6 in 1.00 ->  0.11, target  0.00, metric  0.17\n",
            "7 in 0.00 ->  0.79, target  1.00, metric  0.45\n",
            "8 in 1.00 ->  0.13, target  0.00, metric  0.22\n",
            "9 in 0.00 ->  0.84, target  1.00, metric  0.27\n",
            "10 in 0.00 ->  0.88, target  1.00, metric  0.16\n",
            "11 in 1.00 ->  0.12, target  0.00, metric  0.21\n",
            "12 in 0.00 ->  0.88, target  1.00, metric  0.16\n",
            "13 in 1.00 ->  0.10, target  0.00, metric  0.15\n",
            "14 in 1.00 ->  0.08, target  0.00, metric  0.10\n",
            "15 in 0.00 ->  0.89, target  1.00, metric  0.15\n",
            "16 in 1.00 ->  0.08, target  0.00, metric  0.10\n",
            "17 in 0.00 ->  0.90, target  1.00, metric  0.13\n",
            "18 in 0.00 ->  0.92, target  1.00, metric  0.10\n",
            "19 in 1.00 ->  0.08, target  0.00, metric  0.10\n",
            "20 in 1.00 ->  0.07, target  0.00, metric  0.08\n",
            "21 in 1.00 ->  0.06, target  0.00, metric  0.07\n",
            "22 in 0.00 ->  0.91, target  1.00, metric  0.10\n",
            "23 in 1.00 ->  0.06, target  0.00, metric  0.06\n",
            "24 in 0.00 ->  0.92, target  1.00, metric  0.09\n",
            "25 in 1.00 ->  0.06, target  0.00, metric  0.06\n",
            "26 in 1.00 ->  0.05, target  0.00, metric  0.06\n",
            "27 in 0.00 ->  0.93, target  1.00, metric  0.09\n",
            "28 in 1.00 ->  0.05, target  0.00, metric  0.05\n",
            "29 in 1.00 ->  0.05, target  0.00, metric  0.05\n",
            "30 in 1.00 ->  0.04, target  0.00, metric  0.05\n",
            "31 in 0.00 ->  0.93, target  1.00, metric  0.08\n",
            "32 in 1.00 ->  0.04, target  0.00, metric  0.05\n",
            "33 in 1.00 ->  0.04, target  0.00, metric  0.04\n",
            "34 in 1.00 ->  0.04, target  0.00, metric  0.04\n",
            "35 in 1.00 ->  0.04, target  0.00, metric  0.04\n",
            "36 in 0.00 ->  0.93, target  1.00, metric  0.08\n",
            "37 in 0.00 ->  0.94, target  1.00, metric  0.07\n",
            "38 in 1.00 ->  0.04, target  0.00, metric  0.04\n",
            "39 in 0.00 ->  0.94, target  1.00, metric  0.06\n",
            "40 in 0.00 ->  0.95, target  1.00, metric  0.06\n",
            "41 in 1.00 ->  0.04, target  0.00, metric  0.04\n",
            "42 in 0.00 ->  0.95, target  1.00, metric  0.05\n",
            "43 in 0.00 ->  0.96, target  1.00, metric  0.05\n",
            "44 in 1.00 ->  0.04, target  0.00, metric  0.04\n",
            "45 in 0.00 ->  0.96, target  1.00, metric  0.05\n",
            "46 in 1.00 ->  0.04, target  0.00, metric  0.04\n",
            "47 in 0.00 ->  0.96, target  1.00, metric  0.04\n",
            "48 in 0.00 ->  0.96, target  1.00, metric  0.04\n",
            "49 in 0.00 ->  0.96, target  1.00, metric  0.04\n",
            "50 in 1.00 ->  0.04, target  0.00, metric  0.04\n",
            "51 in 1.00 ->  0.04, target  0.00, metric  0.04\n",
            "52 in 1.00 ->  0.04, target  0.00, metric  0.04\n",
            "53 in 1.00 ->  0.04, target  0.00, metric  0.04\n",
            "54 in 1.00 ->  0.03, target  0.00, metric  0.04\n",
            "55 in 1.00 ->  0.03, target  0.00, metric  0.03\n",
            "56 in 0.00 ->  0.96, target  1.00, metric  0.04\n",
            "57 in 1.00 ->  0.03, target  0.00, metric  0.03\n",
            "58 in 1.00 ->  0.03, target  0.00, metric  0.03\n",
            "59 in 1.00 ->  0.03, target  0.00, metric  0.03\n",
            "60 in 1.00 ->  0.03, target  0.00, metric  0.03\n",
            "61 in 1.00 ->  0.03, target  0.00, metric  0.03\n",
            "62 in 1.00 ->  0.03, target  0.00, metric  0.03\n",
            "63 in 1.00 ->  0.03, target  0.00, metric  0.03\n",
            "64 in 1.00 ->  0.03, target  0.00, metric  0.03\n",
            "65 in 0.00 ->  0.96, target  1.00, metric  0.05\n",
            "66 in 1.00 ->  0.03, target  0.00, metric  0.03\n",
            "67 in 1.00 ->  0.03, target  0.00, metric  0.03\n",
            "68 in 0.00 ->  0.96, target  1.00, metric  0.05\n",
            "69 in 0.00 ->  0.96, target  1.00, metric  0.04\n",
            "70 in 1.00 ->  0.03, target  0.00, metric  0.03\n",
            "71 in 1.00 ->  0.03, target  0.00, metric  0.03\n",
            "72 in 0.00 ->  0.96, target  1.00, metric  0.04\n",
            "73 in 1.00 ->  0.03, target  0.00, metric  0.03\n",
            "74 in 1.00 ->  0.03, target  0.00, metric  0.03\n",
            "75 in 1.00 ->  0.02, target  0.00, metric  0.03\n",
            "76 in 1.00 ->  0.02, target  0.00, metric  0.02\n",
            "77 in 1.00 ->  0.02, target  0.00, metric  0.02\n",
            "78 in 0.00 ->  0.96, target  1.00, metric  0.04\n",
            "79 in 1.00 ->  0.02, target  0.00, metric  0.02\n",
            "80 in 1.00 ->  0.02, target  0.00, metric  0.02\n",
            "81 in 0.00 ->  0.96, target  1.00, metric  0.04\n",
            "82 in 1.00 ->  0.02, target  0.00, metric  0.02\n",
            "83 in 0.00 ->  0.96, target  1.00, metric  0.04\n",
            "84 in 1.00 ->  0.02, target  0.00, metric  0.02\n",
            "85 in 0.00 ->  0.97, target  1.00, metric  0.04\n",
            "86 in 1.00 ->  0.02, target  0.00, metric  0.02\n",
            "87 in 0.00 ->  0.97, target  1.00, metric  0.03\n",
            "88 in 1.00 ->  0.02, target  0.00, metric  0.02\n",
            "89 in 1.00 ->  0.02, target  0.00, metric  0.02\n",
            "90 in 1.00 ->  0.02, target  0.00, metric  0.02\n",
            "91 in 1.00 ->  0.02, target  0.00, metric  0.02\n",
            "92 in 0.00 ->  0.97, target  1.00, metric  0.03\n",
            "93 in 1.00 ->  0.02, target  0.00, metric  0.02\n",
            "94 in 1.00 ->  0.02, target  0.00, metric  0.02\n",
            "95 in 1.00 ->  0.02, target  0.00, metric  0.02\n",
            "96 in 0.00 ->  0.97, target  1.00, metric  0.03\n",
            "97 in 0.00 ->  0.97, target  1.00, metric  0.03\n",
            "98 in 1.00 ->  0.02, target  0.00, metric  0.02\n",
            "99 in 1.00 ->  0.02, target  0.00, metric  0.02\n",
            "--- result ---\n",
            " 0.00 ->  0.97, target  1.00\n",
            " 1.00 ->  0.02, target  0.00\n",
            "--- weights ---\n",
            "p  1 [ 1.381( 1,+), -0.869(-1,-), -1.356(-1,-),  1.041( 1,+)]\n",
            "n -1 [-0.837( 1,+),  0.586(-1,-), -0.044( 1,+),  0.949(-1,-)]\n",
            "p  1 [ 0.932( 1,+), -0.816(-1,-),  0.405( 1,+), -0.851(-1,-)]\n",
            "0 in[ 1.00, 1.00] ->  1.00, target  1.00, metric  0.00\n",
            "1 in[ 1.00, 1.00] ->  1.00, target  1.00, metric  0.00\n",
            "2 in[ 1.00, 1.00] ->  1.00, target  1.00, metric  0.00\n",
            "3 in[ 0.00, 0.00] ->  0.96, target  1.00, metric  0.06\n",
            "4 in[ 1.00, 0.00] ->  0.89, target  0.00, metric  0.99\n",
            "5 in[ 0.00, 0.00] ->  0.92, target  1.00, metric  0.18\n",
            "6 in[ 1.00, 1.00] ->  0.99, target  1.00, metric  0.01\n",
            "7 in[ 1.00, 1.00] ->  0.99, target  1.00, metric  0.01\n",
            "8 in[ 0.00, 0.00] ->  0.95, target  1.00, metric  0.07\n",
            "9 in[ 1.00, 1.00] ->  1.00, target  1.00, metric  0.00\n",
            "10 in[ 1.00, 1.00] ->  1.00, target  1.00, metric  0.00\n",
            "11 in[ 1.00, 0.00] ->  0.35, target  0.00, metric  0.95\n",
            "12 in[ 0.00, 0.00] ->  0.94, target  1.00, metric  0.30\n",
            "13 in[ 1.00, 0.00] ->  0.01, target  0.00, metric  0.70\n",
            "14 in[ 1.00, 1.00] ->  1.00, target  1.00, metric  0.60\n",
            "15 in[ 0.00, 1.00] ->  0.66, target  0.00, metric  1.00\n",
            "16 in[ 1.00, 1.00] ->  0.95, target  1.00, metric  0.08\n",
            "17 in[ 0.00, 1.00] ->  0.00, target  0.00, metric  0.73\n",
            "18 in[ 1.00, 1.00] ->  0.92, target  1.00, metric  0.96\n",
            "19 in[ 1.00, 0.00] ->  0.05, target  0.00, metric  0.17\n",
            "20 in[ 0.00, 0.00] ->  0.79, target  1.00, metric  0.94\n",
            "21 in[ 0.00, 1.00] ->  0.01, target  0.00, metric  0.37\n",
            "22 in[ 0.00, 0.00] ->  0.98, target  1.00, metric  0.77\n",
            "23 in[ 0.00, 0.00] ->  0.98, target  1.00, metric  0.02\n",
            "24 in[ 0.00, 1.00] ->  0.02, target  0.00, metric  0.25\n",
            "25 in[ 0.00, 1.00] ->  0.01, target  0.00, metric  0.02\n",
            "26 in[ 1.00, 0.00] ->  0.00, target  0.00, metric  0.45\n",
            "27 in[ 1.00, 1.00] ->  0.96, target  1.00, metric  0.83\n",
            "28 in[ 0.00, 0.00] ->  0.96, target  1.00, metric  0.06\n",
            "29 in[ 0.00, 0.00] ->  0.96, target  1.00, metric  0.04\n",
            "30 in[ 1.00, 1.00] ->  0.97, target  1.00, metric  0.03\n",
            "31 in[ 0.00, 1.00] ->  0.04, target  0.00, metric  0.11\n",
            "32 in[ 0.00, 0.00] ->  0.96, target  1.00, metric  0.06\n",
            "33 in[ 1.00, 1.00] ->  0.96, target  1.00, metric  0.05\n",
            "34 in[ 0.00, 1.00] ->  0.03, target  0.00, metric  0.05\n",
            "35 in[ 1.00, 1.00] ->  0.96, target  1.00, metric  0.05\n",
            "36 in[ 0.00, 1.00] ->  0.03, target  0.00, metric  0.04\n",
            "37 in[ 1.00, 1.00] ->  0.96, target  1.00, metric  0.05\n",
            "38 in[ 0.00, 0.00] ->  0.96, target  1.00, metric  0.04\n",
            "39 in[ 1.00, 1.00] ->  0.97, target  1.00, metric  0.04\n",
            "40 in[ 0.00, 1.00] ->  0.03, target  0.00, metric  0.04\n",
            "41 in[ 1.00, 0.00] ->  0.00, target  0.00, metric  0.49\n",
            "42 in[ 1.00, 0.00] ->  0.00, target  0.00, metric  0.00\n",
            "43 in[ 1.00, 1.00] ->  0.99, target  1.00, metric  0.61\n",
            "44 in[ 1.00, 1.00] ->  0.99, target  1.00, metric  0.01\n",
            "45 in[ 1.00, 0.00] ->  0.02, target  0.00, metric  0.26\n",
            "46 in[ 1.00, 1.00] ->  0.96, target  1.00, metric  0.05\n",
            "47 in[ 1.00, 1.00] ->  0.96, target  1.00, metric  0.04\n",
            "48 in[ 0.00, 1.00] ->  0.02, target  0.00, metric  0.03\n",
            "49 in[ 1.00, 1.00] ->  0.96, target  1.00, metric  0.04\n",
            "50 in[ 0.00, 0.00] ->  0.95, target  1.00, metric  0.10\n",
            "51 in[ 1.00, 1.00] ->  0.97, target  1.00, metric  0.03\n",
            "52 in[ 1.00, 0.00] ->  0.03, target  0.00, metric  0.05\n",
            "53 in[ 1.00, 1.00] ->  0.97, target  1.00, metric  0.03\n",
            "54 in[ 0.00, 0.00] ->  0.96, target  1.00, metric  0.06\n",
            "55 in[ 0.00, 1.00] ->  0.03, target  0.00, metric  0.06\n",
            "56 in[ 0.00, 0.00] ->  0.96, target  1.00, metric  0.05\n",
            "57 in[ 1.00, 1.00] ->  0.97, target  1.00, metric  0.03\n",
            "58 in[ 1.00, 1.00] ->  0.97, target  1.00, metric  0.03\n",
            "59 in[ 0.00, 1.00] ->  0.03, target  0.00, metric  0.05\n",
            "60 in[ 1.00, 1.00] ->  0.97, target  1.00, metric  0.03\n",
            "61 in[ 1.00, 1.00] ->  0.97, target  1.00, metric  0.03\n",
            "62 in[ 0.00, 1.00] ->  0.02, target  0.00, metric  0.03\n",
            "63 in[ 1.00, 1.00] ->  0.97, target  1.00, metric  0.03\n",
            "64 in[ 0.00, 0.00] ->  0.97, target  1.00, metric  0.04\n",
            "65 in[ 1.00, 0.00] ->  0.04, target  0.00, metric  0.06\n",
            "66 in[ 1.00, 0.00] ->  0.03, target  0.00, metric  0.04\n",
            "67 in[ 1.00, 1.00] ->  0.97, target  1.00, metric  0.03\n",
            "68 in[ 0.00, 0.00] ->  0.97, target  1.00, metric  0.04\n",
            "69 in[ 1.00, 1.00] ->  0.97, target  1.00, metric  0.03\n",
            "70 in[ 1.00, 1.00] ->  0.98, target  1.00, metric  0.03\n",
            "71 in[ 1.00, 1.00] ->  0.98, target  1.00, metric  0.02\n",
            "72 in[ 1.00, 1.00] ->  0.98, target  1.00, metric  0.02\n",
            "73 in[ 1.00, 1.00] ->  0.98, target  1.00, metric  0.02\n",
            "74 in[ 0.00, 1.00] ->  0.03, target  0.00, metric  0.04\n",
            "75 in[ 1.00, 1.00] ->  0.98, target  1.00, metric  0.02\n",
            "76 in[ 1.00, 1.00] ->  0.98, target  1.00, metric  0.02\n",
            "77 in[ 0.00, 1.00] ->  0.02, target  0.00, metric  0.03\n",
            "78 in[ 1.00, 0.00] ->  0.03, target  0.00, metric  0.05\n",
            "79 in[ 0.00, 0.00] ->  0.97, target  1.00, metric  0.04\n",
            "80 in[ 1.00, 1.00] ->  0.98, target  1.00, metric  0.03\n",
            "81 in[ 1.00, 0.00] ->  0.03, target  0.00, metric  0.04\n",
            "82 in[ 1.00, 0.00] ->  0.02, target  0.00, metric  0.03\n",
            "83 in[ 0.00, 1.00] ->  0.02, target  0.00, metric  0.02\n",
            "84 in[ 0.00, 0.00] ->  0.97, target  1.00, metric  0.04\n",
            "85 in[ 1.00, 1.00] ->  0.97, target  1.00, metric  0.03\n",
            "86 in[ 0.00, 0.00] ->  0.97, target  1.00, metric  0.03\n",
            "87 in[ 0.00, 0.00] ->  0.98, target  1.00, metric  0.03\n",
            "88 in[ 1.00, 0.00] ->  0.03, target  0.00, metric  0.03\n",
            "89 in[ 0.00, 0.00] ->  0.98, target  1.00, metric  0.02\n",
            "90 in[ 0.00, 0.00] ->  0.98, target  1.00, metric  0.02\n",
            "91 in[ 0.00, 0.00] ->  0.98, target  1.00, metric  0.02\n",
            "92 in[ 0.00, 1.00] ->  0.02, target  0.00, metric  0.03\n",
            "93 in[ 1.00, 1.00] ->  0.97, target  1.00, metric  0.03\n",
            "94 in[ 1.00, 1.00] ->  0.97, target  1.00, metric  0.03\n",
            "95 in[ 1.00, 1.00] ->  0.98, target  1.00, metric  0.03\n",
            "96 in[ 1.00, 1.00] ->  0.98, target  1.00, metric  0.02\n",
            "97 in[ 0.00, 1.00] ->  0.02, target  0.00, metric  0.03\n",
            "98 in[ 1.00, 1.00] ->  0.98, target  1.00, metric  0.02\n",
            "99 in[ 1.00, 1.00] ->  0.98, target  1.00, metric  0.02\n",
            "--- result ---\n",
            "[ 0.00, 0.00] ->  0.98, target  1.00\n",
            "[ 1.00, 0.00] ->  0.04, target  0.00\n",
            "[ 0.00, 1.00] ->  0.03, target  0.00\n",
            "[ 1.00, 1.00] ->  0.98, target  1.00\n",
            "--- weights ---\n",
            "p  1 [ 0.959( 1,+), -1.139(-1,-), -0.967(-1,-),  0.441( 1,+), -0.939(-1,-),  1.061( 1,+), -1.146(-1,-),  0.889( 1,+), -0.727(-1,-),  1.076( 1,+), -0.368(-1,-),  1.485( 1,+), -1.143(-1,-),  0.811( 1,+), -0.629(-1,-),  1.252( 1,+), -1.554(-1,-),  1.195( 1,+)]\n",
            "n -1 [-1.311( 1,+),  1.172(-1,-), -0.463( 1,+),  1.101(-1,-), -0.224( 1,+),  0.802(-1,-)]\n",
            "p  1 [ 0.238( 1,+), -0.908(-1,-),  0.027( 1,+), -0.452(-1,-),  0.427( 1,+), -0.510(-1,-)]\n",
            "n -1 [-1.133( 1,+),  0.651(-1,-), -0.921( 1,+),  1.336(-1,-), -0.973( 1,+),  0.373(-1,-)]\n",
            "p  1 [ 0.849( 1,+), -0.910(-1,-),  0.262( 1,+), -0.878(-1,-),  0.535( 1,+), -0.773(-1,-)]\n",
            "n -1 [-0.750( 1,+),  1.223(-1,-), -0.469( 1,+),  0.775(-1,-), -0.414( 1,+),  0.535(-1,-)]\n",
            "p  1 [ 1.588( 1,+), -1.405(-1,-),  0.852( 1,+), -0.269(-1,-),  0.805( 1,+), -0.871(-1,-)]\n",
            "n -1 [-1.138( 1,+),  1.228(-1,-), -0.193( 1,+),  0.746(-1,-), -0.440( 1,+),  0.817(-1,-)]\n",
            "p  1 [ 1.338( 1,+), -1.159(-1,-),  0.668( 1,+), -1.056(-1,-),  1.013( 1,+), -0.141(-1,-)]\n",
            "n -1 [-1.256( 1,+),  1.117(-1,-), -1.113( 1,+),  0.810(-1,-), -0.815( 1,+),  0.916(-1,-)]\n",
            "p  1 [ 0.976( 1,+), -0.297(-1,-),  0.638( 1,+), -0.088(-1,-),  0.490( 1,+), -0.860(-1,-)]\n",
            "n -1 [-1.565( 1,+),  1.764(-1,-), -1.050( 1,+),  1.221(-1,-), -0.638( 1,+),  0.774(-1,-)]\n",
            "p  1 [ 1.072( 1,+), -0.398(-1,-),  1.013( 1,+), -0.597(-1,-),  0.851( 1,+), -1.061(-1,-)]\n",
            "n -1 [-1.501( 1,+),  1.038(-1,-), -0.975( 1,+),  0.096(-1,-), -0.763( 1,+),  1.352(-1,-)]\n",
            "p  1 [ 0.906( 1,+), -1.575(-1,-),  1.281( 1,+), -0.749(-1,-),  1.297( 1,+), -0.885(-1,-)]\n",
            "n -1 [-0.349( 1,+),  0.825(-1,-), -0.548( 1,+),  0.891(-1,-), -0.100( 1,+),  0.481(-1,-)]\n",
            "p  1 [ 0.962( 1,+), -0.137(-1,-),  0.937( 1,+), -0.456(-1,-),  0.484( 1,+), -0.537(-1,-)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "\n",
        "# GPUを使用するための設定\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "random.seed(10)  # 乱数のシードを設定\n",
        "\n",
        "\n",
        "def sign(x):  # 符号関数の定義\n",
        "    if x == 0:\n",
        "        return 0\n",
        "    return 1 if x > 0 else -1\n",
        "\n",
        "\n",
        "def relu(x):  # ReLU関数の定義\n",
        "    return x if x > 0 else 0\n",
        "\n",
        "\n",
        "def relu_derivative(x):  # ReLU関数の導関数の定義\n",
        "    return 1 if x > 0 else 0\n",
        "\n",
        "\n",
        "def sigmoid(x, u0=0.4):  # シグモイド関数の定義\n",
        "    return 1 / (1 + math.exp(-2 * x / u0))\n",
        "\n",
        "\n",
        "def sigmoid_derivative(x):  # シグモイド関数の導関数の定義\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "\n",
        "def linear(x):  # 線形関数の定義\n",
        "    return x\n",
        "\n",
        "\n",
        "def linear_derivative(x):  # 線形関数の導関数の定義\n",
        "    return 1\n",
        "\n",
        "\n",
        "class Neuron:  # ニューロンクラスの定義\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_neurons: list[\"Neuron\"],  # 入力ニューロンのリスト\n",
        "        ntype: str,  # ニューロンのタイプ（\"p\": positive, \"n\": negative）\n",
        "        alpha: float = 0.8,  # 学習率\n",
        "        activation=sigmoid,  # 活性化関数\n",
        "        activation_derivative=sigmoid_derivative,  # 活性化関数の導関数\n",
        "    ) -> None:\n",
        "        self.ntype = ntype\n",
        "        self.alpha = alpha\n",
        "        self.activation = activation\n",
        "        self.activation_derivative = activation_derivative\n",
        "\n",
        "        # --- 重みの初期化\n",
        "        self.weights = []\n",
        "        self.weights_operator = []\n",
        "        self.upper_idx_list = []\n",
        "        self.lower_idx_list = []\n",
        "        for i, n in enumerate(in_neurons):\n",
        "            if n.ntype == \"p\":\n",
        "                if ntype == \"p\":\n",
        "                    ope = 1\n",
        "                else:\n",
        "                    ope = -1\n",
        "            else:\n",
        "                if ntype == \"p\":\n",
        "                    ope = -1\n",
        "                else:\n",
        "                    ope = 1\n",
        "            self.weights.append(random.random() * ope)\n",
        "            self.weights_operator.append(n.operator)\n",
        "            if n.ntype == \"p\":\n",
        "                self.upper_idx_list.append(i)\n",
        "            else:\n",
        "                self.lower_idx_list.append(i)\n",
        "\n",
        "        # --- 演算子の設定\n",
        "        self.operator = 1 if ntype == \"p\" else -1\n",
        "        self.weights_operator = [n.operator for n in in_neurons]\n",
        "\n",
        "        # --- 更新インデックスの設定\n",
        "        self.upper_idx_list = []\n",
        "        self.lower_idx_list = []\n",
        "        for i, n in enumerate(in_neurons):\n",
        "            if n.ntype == \"p\":\n",
        "                self.upper_idx_list.append(i)\n",
        "            else:\n",
        "                self.lower_idx_list.append(i)\n",
        "\n",
        "    def forward(self, x):  # 順伝播の計算\n",
        "        assert len(self.weights) == len(x), f\"Weight length ({len(self.weights)}) does not match input length ({len(x)})\"\n",
        "        y = [x[i] * self.weights[i] for i in range(len(self.weights))]\n",
        "        y = sum(y)\n",
        "        self.prev_in = x\n",
        "        self.prev_out = y\n",
        "        y = self.activation(y)\n",
        "        return y\n",
        "\n",
        "    def update_weight(self, delta_out, direct: str):  # 重みの更新\n",
        "        grad = self.activation_derivative(abs(self.prev_out))\n",
        "\n",
        "        if direct == \"upper\":\n",
        "            indices = self.upper_idx_list\n",
        "        else:\n",
        "            indices = self.lower_idx_list\n",
        "\n",
        "        for idx in indices:\n",
        "            _old_w = self.weights[idx]\n",
        "            delta = self.alpha * self.prev_in[idx]\n",
        "            delta *= grad\n",
        "            delta *= delta_out * self.operator * self.weights_operator[idx]\n",
        "            self.weights[idx] += delta\n",
        "\n",
        "            # --- デバッグ用の出力\n",
        "            s = f\"{idx:2d}\"\n",
        "            s += f\", ot_in {self.prev_in[idx]:5.2f}\"\n",
        "            s += f\", f'({self.prev_out:5.2f})={grad:5.2f}\"\n",
        "            s += f\", del_ot {delta_out:5.2f}\"\n",
        "            s += f\", d {delta:6.3f}\"\n",
        "            s += f\", {self.operator:2d} {self.weights_operator[idx]:2d}\"\n",
        "            s += f\", w {_old_w:5.2f} -> {self.weights[idx]:5.2f}\"\n",
        "            # print(s)\n",
        "\n",
        "    def __str__(self):  # ニューロンの情報を文字列で返す\n",
        "        s = f\"{self.ntype} {self.operator:2d}\"\n",
        "        arr = []\n",
        "        for i in range(len(self.weights)):\n",
        "            o = \"+\" if i in self.upper_idx_list else \"-\"\n",
        "            arr.append(f\"{self.weights[i]:6.3f}({self.weights_operator[i]:2d},{o})\")\n",
        "        s += \" [\" + \", \".join(arr) + \"]\"\n",
        "        return s\n",
        "\n",
        "\n",
        "class ThreeLayerModel:  # 3層ニューラルネットワークモデルの定義\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_num: int,  # 入力層のニューロン数\n",
        "        hidden_num: int,  # 中間層のニューロン数\n",
        "        output_num: int,  # 出力層のニューロン数\n",
        "        alpha: float = 0.8,  # 学習率\n",
        "    ) -> None:\n",
        "        # 入力層のニューロン\n",
        "        inputs: list[Neuron] = []\n",
        "        for i in range(input_num):\n",
        "            inputs.append(Neuron([], \"p\"))\n",
        "\n",
        "        # 中間層のニューロン\n",
        "        prev_neurons = inputs\n",
        "        self.hidden_neurons: list[Neuron] = []\n",
        "        for i in range(hidden_num):\n",
        "            self.hidden_neurons.append(\n",
        "                Neuron(\n",
        "                    prev_neurons,\n",
        "                    ntype=(\"p\" if i % 2 == 1 else \"n\"),\n",
        "                    alpha=alpha,\n",
        "                    activation=sigmoid,\n",
        "                    activation_derivative=sigmoid_derivative,\n",
        "                )\n",
        "            )\n",
        "            prev_neurons = [self.hidden_neurons[-1]]\n",
        "\n",
        "        # 出力層のニューロン\n",
        "        self.out_neurons: list[Neuron] = []\n",
        "        for i in range(output_num):\n",
        "            self.out_neurons.append(\n",
        "                Neuron(\n",
        "                    prev_neurons,\n",
        "                    \"p\",\n",
        "                    alpha=alpha,\n",
        "                    activation=sigmoid,\n",
        "                    activation_derivative=sigmoid_derivative,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    @tf.function\n",
        "    def forward(self, inputs):  # 順伝播の計算\n",
        "        # 入力層\n",
        "        x = inputs\n",
        "\n",
        "        # 中間層\n",
        "        for h in self.hidden_neurons:\n",
        "            x = h.forward(x)\n",
        "\n",
        "        # 出力層\n",
        "        outputs = []\n",
        "        for n in self.out_neurons:\n",
        "            output = n.forward(x)\n",
        "            outputs.append(output)\n",
        "        outputs = tf.concat(outputs, axis=0)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    @tf.function\n",
        "    def train(self, inputs, targets):  # 学習\n",
        "        with tf.GradientTape() as tape:\n",
        "            outputs = self.forward(inputs)\n",
        "            loss = tf.reduce_mean(tf.square(targets - outputs))\n",
        "\n",
        "        # --- 重みの更新（ED法）\n",
        "        for i in range(len(self.out_neurons)):\n",
        "            diff = targets[i] - outputs[i]\n",
        "            if diff > 0:\n",
        "                direct = \"upper\"\n",
        "            else:\n",
        "                direct = \"lower\"\n",
        "                diff = -diff\n",
        "            self.out_neurons[i].update_weight(diff, direct)\n",
        "            for h in self.hidden_neurons:\n",
        "                h.update_weight(diff, direct)\n",
        "\n",
        "        return loss\n",
        "\n",
        "def main_mnist():  # MNISTの手描き文字の学習\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    # 画像を0-1の範囲に正規化\n",
        "    x_train = x_train.astype('float32') / 255\n",
        "    x_test = x_test.astype('float32') / 255\n",
        "\n",
        "    # 画像を1次元に変換\n",
        "    x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "    x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "    # ラベルをone-hotエンコーディング\n",
        "    y_train = np.eye(10)[y_train]\n",
        "    y_test = np.eye(10)[y_test]\n",
        "\n",
        "    model = ThreeLayerModel(input_num=784, hidden_num=128, output_num=10)\n",
        "\n",
        "    # --- 学習ループ\n",
        "    num_epochs = 10\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        train_loss = 0\n",
        "        for i in range(len(x_train)):\n",
        "            inputs = x_train[i]\n",
        "            targets = y_train[i]\n",
        "            loss = model.train(inputs, targets)\n",
        "            train_loss += loss\n",
        "        train_loss /= len(x_train)\n",
        "        print(f\"Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "        # --- テストデータでの評価\n",
        "        correct = 0\n",
        "        for i in range(len(x_test)):\n",
        "            inputs = x_test[i]\n",
        "            targets = y_test[i]\n",
        "            outputs = model.forward(inputs)\n",
        "            predicted = np.argmax(outputs)\n",
        "            if predicted == np.argmax(targets):\n",
        "                correct += 1\n",
        "        accuracy = correct / len(x_test)\n",
        "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_mnist()  # MNISTの手描き文字の学習を実行"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "ouM1w0_C3_b5",
        "outputId": "ca4ef923-3c68-424e-aa12-8d3fa56405e9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "in user code:\n\n    File \"<ipython-input-17-ee3664874aba>\", line 201, in train  *\n        outputs = self.forward(inputs)\n    File \"<ipython-input-17-ee3664874aba>\", line 187, in forward  *\n        x = h.forward(x)\n    File \"<ipython-input-17-ee3664874aba>\", line 101, in forward  *\n        y = self.activation(y)\n    File \"<ipython-input-17-ee3664874aba>\", line 30, in sigmoid  *\n        return 1 / (1 + math.exp(-2 * x / u0))\n\n    TypeError: must be real number, not SymbolicTensor\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ee3664874aba>\u001b[0m in \u001b[0;36m<cell line: 261>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     \u001b[0mmain_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# MNISTの手描き文字の学習を実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-ee3664874aba>\u001b[0m in \u001b[0;36mmain_mnist\u001b[0;34m()\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filekc228m7b.py\u001b[0m in \u001b[0;36mtf__train\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file5c1fmce3.py\u001b[0m in \u001b[0;36mtf__forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'h'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file5c1fmce3.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0;32mnonlocal\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'h'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filedka6zo89.py\u001b[0m in \u001b[0;36mtf__forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filejjzgsz60.py\u001b[0m in \u001b[0;36mtf__sigmoid\u001b[0;34m(x, u0)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"<ipython-input-17-ee3664874aba>\", line 201, in train  *\n        outputs = self.forward(inputs)\n    File \"<ipython-input-17-ee3664874aba>\", line 187, in forward  *\n        x = h.forward(x)\n    File \"<ipython-input-17-ee3664874aba>\", line 101, in forward  *\n        y = self.activation(y)\n    File \"<ipython-input-17-ee3664874aba>\", line 30, in sigmoid  *\n        return 1 / (1 + math.exp(-2 * x / u0))\n\n    TypeError: must be real number, not SymbolicTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1DPLFv793_eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e7bMY0-J3_gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lBad9xWw3_iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Input(shape=(28 * 28)),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_one()\n",
        "    main_not()\n",
        "    main_xor()"
      ],
      "metadata": {
        "id": "JBmAhntPBhfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ikH16vOJBpC4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}